#' Coverage summary
#'
#' Summarise coverage (.cov) files generated by bismark in a given directory. An annotation file, containing specific genomic co-ordinates per row, can be given to provide summary level of cytosine within the ranges provided.
#' 
#' @param cov.dir directory containing .cov files.
#' @param output.dir Directory to save results table. Default is location of 'cov.dir' provided.
#' @param cov.suffix Ending pattern to match and identify files. Default is 'cov.gz'.
#' @param chr.to.keep Select chromosomes to keep. Default = c(1:22,"X", "Y", "y", "x")
#' @param anno Annotation file. Needs to be file that has a dataframe with columns 'chr', 'start' and 'end' at the very least. The script will then summary statistics for all the whole cov (filtered by selected chr's) + cytosines within the ranges provided in this file. Default is 'NULL'.
#' @param run.parallel Logical. Whether or not to run using parallel processing. Should work for both Unix and windows... (untested in mac)
#' @param n.cores Numeric. Optional to specify with parallel processing. If n.cores = NA & run.parallel = TRUE, the script will identify total available cores and use 1-total. Advise not using 'all cores' if it's on your local machine.
#' @return genome fasta
#' @examples 
#' cov_summary(cov.dir = system.file("extdata", package = "covSummary"), output.dir = "./test")
#' @import dplyr
#' @import data.table
#' @import GenomicRanges
#' @import GenomeInfoDb
#' @import foreach
#' @import R.utils
#' @export
cov_summary <- function(cov.dir = "./data/",
                        output.dir = "", 
                        cov.suffix = "cov.gz", 
                        chr.to.keep = c(1:22,"X", "Y", "y", "x"), #
                        anno = "NULL", 
                        run.parallel = FALSE,
                        n.cores = NA){ # USE WITH CAUTION. This needs to be numeric and is only considered if run.parallel = TRUE. Only use this if you know exactly how many core you intend to use! By default, the function will detect all available cores detected and -1 from this, which is important when running on PC as you need 1 core to allow you do other things.
  
  
  # If no output dir is specified, the input dir will be used.
  if(output.dir == "") output.dir = cov.dir
  # Checks if output dir exists, if it doesn't, R will attempt to create it.
  if (!dir.exists(output.dir)) {dir.create(output.dir)}
  
  run.parallel <- run.parallel
  
  # Read anno file if provided ####
  
  if(anno != "NULL"){
    ### Read in annotations of interest ###
    
    cat("Reading in annotation file: ", anno)
    
    AnnoData=fread(anno)
    AnnoGR=makeGRangesFromDataFrame(AnnoData, start.field=c("start","begin"), end.field=c("end","stop"), seqnames.field = c("chr","Chromosome"), ignore.strand = T)
    seqlevelsStyle(AnnoGR)<-"NCBI"
  }
  
  # List and read in all cov files
  
  covfiles=list.files(cov.dir, pattern = cov.suffix, full.names = TRUE) %>% .[order(.)]
  cat("\nFound", length(covfiles), "cov files to import.\n")
  if(length(covfiles)>300) message("If analysing a lot of samples (>300), it's worth running in parallel. Either way, consider testing the time taken to run a subset of files.")
  
  #covfiles=covfiles[1:10] ### To test the script on a small number of samples, unhash this line ###
  Cov_summary <- NULL
  
  #------------------------------------------------------------------------------------------#
  # No anno + No parallel ####
  #------------------------------------------------------------------------------------------#
  
  if(anno == "NULL" & run.parallel == FALSE){
    message("\nIf this is a TEM-seq library, it is highly recommend that you obtain the SINE-Alu annotation prior to running this to obtain all the relevant QC metrics.")
    message("\nFor now, this will still obtain the 'global methylation level' for each sample, without the additional QC info.")
    message("\nThis will be run on a single core.")
    
    Cov_summary <- foreach(cov = covfiles, .inorder=FALSE, .combine = 'rbind', .export ='data.table', .packages = c("data.table", "dplyr", "R.utils")) %do% { # To make this parallelised, change this to '%dopar%'
      #library(data.table)
      #library(dplyr)
      #library(R.utils)
      cat("\nProcessing file: ", cov)
      
      # Read in cov file
      tmp <- fread(cov, col.names = c("chromosome","start","end","methylation_percentage","count_methylated","count_unmethylated"))
      
      # Filter for chrs to keep
      tmp <- tmp %>% 
        filter(chromosome %in% chr.to.keep)
      
      # Detect any duplicate CpGs
      n_duplicates <- tmp %>%
        group_by(chromosome, start,end) %>%
        duplicated(.) %>% sum(.)
      
      # If there are duplicate CpGs - merge cov counts
      if(n_duplicates > 0) {
        cat("\nDetected duplicate CpGs, merging dups by chr and pos.")
        tmp <- tmp %>%
          filter(chromosome %in% chr.to.keep) %>%
          group_by(chromosome, start, end) %>%
          summarise(
            count_methylated   = sum(count_methylated,   na.rm = TRUE),
            count_unmethylated = sum(count_unmethylated, na.rm = TRUE),
            .groups = "drop"
          ) %>%
          mutate(
            total = count_methylated + count_unmethylated,
            methylation_percentage = ifelse(total > 0, 100 * count_methylated / total, NA_real_)
          ) %>%
          select(chromosome, start, end, methylation_percentage,
                 count_methylated, count_unmethylated)
        
      }
      
      # Summarise cov
      tmp <- tmp %>% 
        summarise(cov_file = basename(cov),
                  N_unique_cytosines = length(methylation_percentage),
                  Average_methylation = mean(methylation_percentage), # This is preferable, because sum of cytosines (methylated and unmethylated) gives too much weight to positions covered more than once.
                  Percent_digital = (N_unique_cytosines - sum(methylation_percentage != 100 & methylation_percentage !=0))/ N_unique_cytosines *100,
                  N_dup_cytosines_in_cov = n_duplicates,
                  N_met_cytosines = sum(count_methylated),
                  N_cytosine_measured = sum(count_methylated + count_unmethylated))
    }
    
    
    #------------------------------------------------------------------------------------------#
    # No anno + parallel ####
    #------------------------------------------------------------------------------------------#
  } else if(anno == "NULL" & run.parallel == TRUE){
    
    cat(paste0("\nNo annotation provided."))
    #library(doParallel)
    cat(paste0("\nPerforming parallel processing"))
    N_CORES <- parallel::detectCores() # Detect how many cores are available
    cat(paste0("\nDetected total available 'N_CORES': ", N_CORES,"\n"))
    # Accounting for user specified 'n.cores' in relation to total detected cores...
    
    if(is.numeric(n.cores) & n.cores <= N_CORES){
      cat("\nSpecified 'n.cores': ", n.cores)
      message("\nn.cores less than or equal to detected, using specified 'n.cores'")
      N_CORES <- n.cores
    } else if(is.numeric(n.cores) & n.cores > N_CORES) {
      cat("\nSpecified 'n.cores': ", n.cores)
      message("\nn.cores is greater than detected. For safety, returning to default behaviour, N_CORES = total detected-1")
      N_CORES = N_CORES-1
    } else if(!is.numeric(n.cores)) {
      cat("\n'n.cores' not specified (or detected as numeric), using default behaviour, N_CORES = total detected-1")
      N_CORES = N_CORES-1
    }
    cat("\n\nUtilising", N_CORES, "cores")
    
    
    my.cl <- parallel::makeCluster((N_CORES), type = "PSOCK") # Make cluster using 'socket' which works across unix and windows! Using 1 core less than totally available to allow for other work to be done while waiting.
    doParallel::registerDoParallel(cl = my.cl) # Register parallel options
    
    # Add progress log (https://www.r-bloggers.com/2012/02/monitoring-progress-inside-a-foreach-loop/)
    writeLines(c(""), "cov_log.txt")
    #sink("cov_log.txt", append=TRUE)
    
    Cov_summary <- foreach(cov.name = covfiles, .inorder=FALSE, .combine = 'rbind', .export ='data.table', .packages = c("data.table", "dplyr", "R.utils")) %dopar% { # To make this parallelised, change this to '%dopar%'
      #library(data.table)
      #library(dplyr)
      #library(GenomicRanges)
      
      # Read in cov file
      cov <- fread(cov.name, col.names = c("chromosome","start","end","methylation_percentage","count_methylated","count_unmethylated"))
      
      # Add progress to log file
      sink("cov_log.txt", append=TRUE)
      cat(paste0("\nStarting file: ",cov.name))
      
      # Filter for chr
      tmp <- cov %>% 
        filter(chromosome %in% chr.to.keep)
      
      # Detect any duplicate CpGs
      n_duplicates <- tmp %>%
        group_by(chromosome, start,end) %>%
        duplicated(.) %>% sum(.)
      
      # If there are duplicate CpGs - merge cov counts
      if(n_duplicates > 0) {
        cat("\nDetected duplicate CpGs, merging dups by chr and pos.")
        tmp <- tmp %>%
          filter(chromosome %in% chr.to.keep) %>%
          group_by(chromosome, start, end) %>%
          summarise(
            count_methylated   = sum(count_methylated,   na.rm = TRUE),
            count_unmethylated = sum(count_unmethylated, na.rm = TRUE),
            .groups = "drop"
          ) %>%
          mutate(
            total = count_methylated + count_unmethylated,
            methylation_percentage = ifelse(total > 0, 100 * count_methylated / total, NA_real_)
          ) %>%
          select(chromosome, start, end, methylation_percentage,
                 count_methylated, count_unmethylated)
      }
      
      # Summarise cov
      tmp <- tmp %>% 
        summarise(cov_file = basename(cov.name),
                  N_unique_cytosines = length(methylation_percentage),
                  Average_methylation = mean(methylation_percentage), # This is preferable, because sum of cytosines (methylated and unmethylated) gives too much weight to positions covered more than once.
                  Percent_digital = (N_unique_cytosines - sum(methylation_percentage != 100 & methylation_percentage !=0))/ N_unique_cytosines *100,
                  N_dup_cytosines_in_cov = n_duplicates,
                  N_met_cytosines = sum(count_methylated),
                  N_cytosine_measured = sum(count_methylated + count_unmethylated))
      
      
    }
    
    
    #------------------------------------------------------------------------------------------#
    # Anno + No parallel ####
    #------------------------------------------------------------------------------------------#
    
  } else if(anno != "NULL" & run.parallel == FALSE){
    message("\nLooping the import and global methylation estimation on a single core. This may take some time... Enjoy a coffee or tea!\n")
    
    Cov_summary <- foreach(cov.name = covfiles, .inorder=FALSE, .combine = 'rbind', .export ='data.table', .packages = c("data.table", "dplyr", "R.utils", "GenomicRanges")) %do% { # To make this parallelised, change this to '%dopar%'
      #library(data.table)
      #library(dplyr)
      
      cat("\nProcessing file: ", cov.name)
      #setwd(cov.dir)
      
      # Read in cov file
      cov <- fread(cov.name, data.table = T, col.names = c("chromosome","start","end","methylation_percentage","count_methylated","count_unmethylated"))
      
      # Filter for chr
      tmp <- cov %>% 
        filter(chromosome %in% chr.to.keep)
      
      # Detect any duplicate CpGs
      n_duplicates <- tmp %>%
        group_by(chromosome, start,end) %>%
        duplicated(.) %>% sum(.)
      
      # If there are duplicate CpGs - merge cov counts
      if(n_duplicates > 0) {
        cat("\nDetected duplicate CpGs, merging dups by chr and pos.")
        tmp <- tmp %>%
          filter(chromosome %in% chr.to.keep) %>%
          group_by(chromosome, start, end) %>%
          summarise(
            count_methylated   = sum(count_methylated,   na.rm = TRUE),
            count_unmethylated = sum(count_unmethylated, na.rm = TRUE),
            .groups = "drop"
          ) %>%
          mutate(
            total = count_methylated + count_unmethylated,
            methylation_percentage = ifelse(total > 0, 100 * count_methylated / total, NA_real_)
          ) %>%
          select(chromosome, start, end, methylation_percentage,
                 count_methylated, count_unmethylated)
      }
      
      # Find overlaps with annotation
      GR1=makeGRangesFromDataFrame(tmp, start.field="start", end.field="end", seqnames.field = "chromosome", ignore.strand = T)
      GR1=keepSeqlevels(GR1, value=intersect(seqlevels(GR1),seqlevels(AnnoGR)), pruning.mode = "tidy")
      overlap=findOverlaps(GR1,AnnoGR, minoverlap=1, maxgap= -1)
      
      # Summarise cov
      tmp <- tmp %>% 
        summarise(cov_file = basename(cov.name),
                  N_unique_cytosines = length(methylation_percentage),
                  Average_methylation = mean(methylation_percentage), # This is preferable, because sum of cytosines (methylated and unmethylated) gives too much weight to positions covered more than once.
                  Percent_digital = (N_unique_cytosines - sum(methylation_percentage != 100 & methylation_percentage !=0))/ N_unique_cytosines *100,
                  N_dup_cytosines_in_cov = n_duplicates,
                  N_met_cytosines = sum(count_methylated),
                  N_cytosine_measured = sum(count_methylated + count_unmethylated),
                  
                  # Anno specific
                  N_anno_detected = length(unique(overlap@to)),
                  N_unique_cytosines_in_anno = length(unique(overlap@from)),
                  Percent_Unique_cytosines_in_anno = N_unique_cytosines_in_anno / N_unique_cytosines*100,
                  Average_methylation_Anno_only = mean(methylation_percentage[overlap@from]),
                  N_met_cytosines_in_anno = sum(count_methylated[overlap@from]),
                  N_cytosine_measured_in_anno = sum(count_methylated[overlap@from] + count_unmethylated[overlap@from])
        )
    }
    
    #------------------------------------------------------------------------------------------#
    # Anno + parallel ####
    #------------------------------------------------------------------------------------------#
  } else if(anno != "NULL" & run.parallel == TRUE){
    #library(doParallel)
    cat(paste0("\nPerforming parallel processing"))
    N_CORES <- parallel::detectCores() # Detect how many cores are available
    cat(paste0("\nDetected total available 'N_CORES': ", N_CORES,"\n"))
    # Accounting for user specified 'n.cores' in relation to total detected cores...
    if(is.numeric(n.cores) & n.cores <= N_CORES){
      cat("\nSpecified 'n.cores': ", n.cores)
      message("\nn.cores less than or equal to detected, using specified 'n.cores'")
      N_CORES <- n.cores
    } else if(is.numeric(n.cores) & n.cores > N_CORES) {
      cat("\nSpecified 'n.cores': ", n.cores)
      message("\nn.cores is greater than detected. For safety, returning to default behaviour, N_CORES = total detected-1")
      N_CORES = N_CORES-1
    } else if(!is.numeric(n.cores)) {
      cat("\n'n.cores' not specified (or detected as numeric), using default behaviour, N_CORES = total detected-1")
      N_CORES = N_CORES-1
    }
    cat("\n\nUtilising", N_CORES, "cores")
    
    
    my.cl <- parallel::makeCluster((N_CORES), type = "PSOCK") # Make cluster using 'socket' which works across unix and windows! Using 1 core less than totally available to allow for other work to be done while waiting.
    doParallel::registerDoParallel(cl = my.cl) # Register parallel options
    
    # Add progress log (https://www.r-bloggers.com/2012/02/monitoring-progress-inside-a-foreach-loop/)
    writeLines(c(""), "cov_log.txt")
    #sink("cov_log.txt", append=TRUE)
    
    Cov_summary <- foreach(cov.name = covfiles, .inorder=FALSE, .combine = 'rbind', .export ='data.table', .packages = c("data.table", "dplyr", "GenomicRanges", "R.utils")) %dopar% { # To make this parallelised, change this to '%dopar%'
      #library(data.table)
      #library(dplyr)
      #library(GenomicRanges)
      
      # Read in cov file
      cov <- fread(cov.name, col.names = c("chromosome","start","end","methylation_percentage","count_methylated","count_unmethylated"))
      
      # Add progress to log file
      sink("cov_log.txt", append=TRUE)
      cat(paste0("\nStarting file: ",cov.name))
      
      # Filter for chr
      tmp <- cov %>% 
        filter(chromosome %in% chr.to.keep)
      
      # Detect any duplicate CpGs
      n_duplicates <- tmp %>%
        group_by(chromosome, start,end) %>%
        duplicated(.) %>% sum(.)
      
      # If there are duplicate CpGs - merge cov counts
      if(n_duplicates > 0) {
        cat("\nDetected duplicate CpGs, merging dups by chr and pos.")
        tmp <- tmp %>%
          filter(chromosome %in% chr.to.keep) %>%
          group_by(chromosome, start, end) %>%
          summarise(
            count_methylated   = sum(count_methylated,   na.rm = TRUE),
            count_unmethylated = sum(count_unmethylated, na.rm = TRUE),
            .groups = "drop"
          ) %>%
          mutate(
            total = count_methylated + count_unmethylated,
            methylation_percentage = ifelse(total > 0, 100 * count_methylated / total, NA_real_)
          ) %>%
          select(chromosome, start, end, methylation_percentage,
                 count_methylated, count_unmethylated)
      }
      
      # Find overlap
      GR1=makeGRangesFromDataFrame(tmp, start.field="start", end.field="end", seqnames.field = "chromosome", ignore.strand = T)
      GR1=keepSeqlevels(GR1, value=intersect(seqlevels(GR1),seqlevels(AnnoGR)), pruning.mode = "tidy")
      overlap=findOverlaps(GR1,AnnoGR, minoverlap=1, maxgap= -1)
      
      # Summarise cov
      tmp <- tmp %>% 
        summarise(cov_file = basename(cov.name),
                  N_unique_cytosines = length(methylation_percentage),
                  Average_methylation = mean(methylation_percentage), # This is preferable, because sum of cytosines (methylated and unmethylated) gives too much weight to positions covered more than once.
                  Percent_digital = (N_unique_cytosines - sum(methylation_percentage != 100 & methylation_percentage !=0))/ N_unique_cytosines *100,
                  N_dup_cytosines_in_cov = n_duplicates,
                  N_met_cytosines = sum(count_methylated),
                  N_cytosine_measured = sum(count_methylated + count_unmethylated),
                  
                  # Anno specific
                  N_anno_detected = length(unique(overlap@to)),
                  N_unique_cytosines_in_anno = length(unique(overlap@from)),
                  Percent_Unique_cytosines_in_anno = N_unique_cytosines_in_anno / N_unique_cytosines*100,
                  Average_methylation_Anno_only = mean(methylation_percentage[overlap@from]),
                  N_met_cytosines_in_anno = sum(count_methylated[overlap@from]),
                  N_cytosine_measured_in_anno = sum(count_methylated[overlap@from] + count_unmethylated[overlap@from])
        )
      
    }
    # Move log progress file
    stopCluster(my.cl)
    file.rename(from="cov_log.txt",
                to=paste0(output.dir,"/cov_log.txt"))

  }
  
  # Save 
  message("\nFinished processing ", length(covfiles), " cov files.")
  cat("\nSaving results to: ", paste0(output.dir,"/Coverage_Summary.txt"))
  write.table(Cov_summary, file = paste0(output.dir,"/Coverage_Summary.tsv"), sep ="\t", quote = F, row.names = F)
  
}